import pymongo
from datetime import timedelta, timezone, datetime
import time
import requests
import gzip
import os

mongo = pymongo.MongoClient(os.environ['MONGO_URI'])
db = mongo["cve_storage"]
epss_db = db['epss']

hours = 12
last_days = 30

def splitepss(line):
    line = line.rstrip('\n')
    tokens = line.split(',')
    return tokens[0], tokens[1], tokens[2]

def downloadepss(url = "https://epss.cyentia.com/epss_scores-current.csv.gz"):
    filename = 'epss.csv.gz' 
    response = requests.get(url, stream=True)
    with open(filename, 'wb') as file:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    file.write(chunk)
    with gzip.open(filename, 'rt', encoding='utf-8') as file:
         file_lines = file.readlines()
         time = file_lines[0].split(',')[1].split(':', 1)[1].strip()
         time = datetime.strptime(time, "%Y-%m-%dT%H:%M:%S%z")
         return time, file_lines[2:]
    

def processandstore(formattedtime, downloaded):
    temp_dict = {'date': formattedtime}
    for line in downloaded:
        cve, epss, pctl = splitepss(line)
        detailsdict = {'epss': epss, 'pctl': pctl}
        temp_dict[cve] = detailsdict
    epss_db.insert_one(temp_dict)  

def getlastentryrecord():
    entry = epss_db.find({}, {'_id': -1, 'date': 1}).sort({'date': -1}).limit(1).next()
    return entry['date']

def clearallrecords():
    epss_db.drop()
    
def deletelatestentryrecords(limit = last_days):
    entry = list(epss_db.find({}, {'_id': 1, 'date': 1}).sort({'date': 1}).limit(limit))
    delete_ids = [record['_id'] for record in entry]
    epss_db.delete_many({'_id': {'$in': delete_ids}})

def updatehandler():
    date_list = []
    filetime, _ = downloadepss()
    filetime = filetime.replace(tzinfo=timezone.utc)
    # Check if last updated date is more than 30 days ago
    latestentrydate = getlastentryrecord()
    latestentrydate = latestentrydate.replace(tzinfo=timezone.utc)
    if ((filetime - timedelta(days=last_days)) > latestentrydate):
        clearallrecords()
        first_time()
    else:
        while latestentrydate < filetime:
            latestentrydate += timedelta(days=1)
            date_list.append(latestentrydate.strftime("%Y-%m-%d"))
    return date_list
    
def downloadandupdatedb(date_list):
    for date in date_list:
        url = f'https://epss.cyentia.com/epss_scores-{date}.csv.gz'
        filetime, downloaded = downloadepss(url)
        processandstore(filetime, downloaded)

def first_time():
    filetime, downloaded = downloadepss()
    print(f"Downloading EPSS for {filetime.strftime('%Y-%m-%d')}")
    processandstore(filetime, downloaded)

    dates = [(filetime - timedelta(days=i)).strftime("%Y-%m-%d") for i in range(1, last_days)]

    for date in dates:
        print(f"Downloading EPSS for {date}")
        url = f'https://epss.cyentia.com/epss_scores-{date}.csv.gz'
        filetime, downloaded = downloadepss(url)
        processandstore(filetime, downloaded)

def update():
    date_list = updatehandler()
    if date_list:
        downloadandupdatedb(date_list)
        deletelatestentryrecords(len(date_list))

# Debug purposes to list all dates
def checkdates():
    entry = list(epss_db.find({}, {'_id': 1, 'date': 1}).sort({'date': 1}))
    for i in entry:
        print(i)

def checkemptycollection():
    if epss_db.count_documents({}) == 0:
        return True
    else:
        return False

if __name__ == "__main__":
    while 1:
        try:
            if checkemptycollection():
                first_time()
            else:
                update()
            current_time = datetime.now().strftime("%d-%m-%Y %H:%M")
            print(f"EPSS statistics last checked/updated at {current_time}")
            time.sleep(hours*60*60)
        except requests.exceptions.ConnectionError:
            print("No internet connection, retrying in 1 minute")
            time.sleep(60)